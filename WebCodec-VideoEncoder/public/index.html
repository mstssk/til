<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WebCodec VideoEncoder</title>
</head>

<body>

  <h1>WebCodec VideoEncoder</h1>

  <button id="start">Start Recoding</button><br>

  <!-- <video id="video" autoplay controls></video> -->

  <script type="module">
    import { Muxer, ArrayBufferTarget } from "https://www.unpkg.com/webm-muxer@4.0.1/build/webm-muxer.mjs";

    const start = document.getElementById('start');

    start.addEventListener('click', async () => {
      const displayStream = await navigator.mediaDevices.getDisplayMedia({
        video: {
          width: { max: 1920 },
          height: { max: 1080 },
          frameRate: { ideal: 30, max: 30 },
        },
      });


      /** @type {number} */
      let lastTimestamp = 0;
      const timestamps = [];

      /** @type {HTMLCanvasElement} */
      const canvas = await new Promise((resolve) => {
        /** @type {HTMLCanvasElement} */
        let canvas;
        new MediaStreamTrackProcessor({ track: displayStream.getVideoTracks()[0] })
          .readable.pipeTo(new WritableStream({
            /** @param {VideoFrame} frame */
            write: (frame) => {

              // fpsの計算
              timestamps.push(document.timeline.currentTime);
              // console.log(document.timeline.currentTime, lastTimestamp, document.timeline.currentTime - lastTimestamp);
              if (document.timeline.currentTime - lastTimestamp > 1000) {
                console.log(timestamps.length, "fps");
                timestamps.splice(0); // clear
                lastTimestamp = document.timeline.currentTime;
              }

              if (!canvas) {
                canvas = document.createElement('canvas');
                resolve(canvas);
                // document.body.appendChild(canvas);
              }
              canvas.width = frame.displayWidth;
              canvas.height = frame.displayHeight;
              canvas.getContext('2d').drawImage(frame, 0, 0, frame.displayWidth, frame.displayHeight);
              frame.close();
            },
          }));
      });
      const width = canvas.width;
      const height = canvas.height;
      console.log(width, height, canvas);
      const captureStream = canvas.captureStream(30);

      const muxer = new Muxer({
        target: new ArrayBufferTarget(),
        video: {
          codec: 'V_VP9',
          width: width,
          height: height,
          frameRate: 30,
        },
        firstTimestampBehavior: 'offset',
        // streaming: true,
      });

      let start;
      const videoEncoder = new VideoEncoder({
        output: (chunk, metadata) => {
          if (!start) {
            start = new Date();
          }
          // console.log(videoEncoder.state);
          // console.log(chunk);
          if (metadata.decoderconfig) {
            console.log("decoderconfig", metadata.decoderconfig);
          }
          muxer.addVideoChunk(chunk, metadata)
        },
        error: (e) => console.error(e.message)
      });
      videoEncoder.configure({
        codec: "vp09.00.10.08",
        // hardwareAcceleration: "prefer-software",
        // ストリームの実際の解像度とフレームレートを指定する場合、ストリームを一度Video要素に書き出す必要があり面倒。
        width: width,
        height: height,
        framerate: 30,
        bitrate: 6 * 1000 * 1000, // 6Mbps
      });

      displayStream.getVideoTracks().forEach(track => {
        track.onended = async () => {
          captureStream.getTracks().forEach(track => track.stop());
          await videoEncoder.flush();
          videoEncoder.close();
          muxer.finalize();
          console.log("Recorded duration", (new Date() - start) / 1000);

          const blob = new Blob([muxer.target.buffer], { type: 'video/webm' });
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.setAttribute('href', url);
          a.setAttribute('download', 'video.webm');
          a.click();
          URL.revokeObjectURL(url);

        };
      });

      let lastKeyFrameTime = -Infinity;
      new MediaStreamTrackProcessor({ track: captureStream.getVideoTracks()[0] })
        .readable.pipeTo(new WritableStream({
          write: (frame) => {
            const keyFrame = document.timeline.currentTime - lastKeyFrameTime > 5_000;
            if (keyFrame) {
              lastKeyFrameTime = document.timeline.currentTime;
              console.log("keyFrame");
            }
            videoEncoder.encode(frame, { keyFrame });
            frame.close();
          },
        }));
    });

  </script>

</body>

</html>
